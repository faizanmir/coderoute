# ===================================================================
# CORE APPLICATION SETTINGS
# ===================================================================
# Defines the name of your application, which is useful for logging and management.
spring.application.name=coderoute

# Sets the port on which the embedded web server will run.
server.port=8080


# ===================================================================
# SPRING AI (OLLAMA) CONFIGURATION
# ===================================================================
# This section configures the connection to your Ollama instance.
# When running inside Docker Compose, you must use the service name ('ollama') as the hostname, not 'localhost'.
spring.ai.ollama.base-url=http://ollama:11434

# Specifies which Ollama model to use for the chat completions.
# Make sure you have pulled this model (e.g., 'ollama pull llama3').
spring.ai.ollama.chat.options.model=llama3

# You can adjust other options like temperature for creativity vs. factuality (0.0 to 1.0)
spring.ai.ollama.chat.options.temperature=0.4
# ===================================================================
# MONGODB REACTIVE CONFIGURATION (DISABLED BY DEFAULT)
# ===================================================================
# Your project includes the MongoDB dependency. If you intend to use MongoDB instead of H2,
# uncomment the following line and comment out the H2/JPA section above.
# When running in Docker, the URI should point to the MongoDB service name, not 'localhost'.
spring.data.mongodb.uri=mongodb://mongo:27017/coderoute


# ===================================================================
# REDIS CONFIGURATION (DISABLED BY DEFAULT)
# ===================================================================
# Your project includes the Redis dependency. If you need Redis (e.g., for caching),
# uncomment the following lines. When running in Docker, the host should be the Redis service name.
# spring.data.redis.host=redis
# spring.data.redis.port=6379

